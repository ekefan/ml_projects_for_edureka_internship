{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ef4077-5d18-42c3-befd-1024a7a72bba",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue\">DATA SCIENCE AND MACHINE LEARNING INTERNSHIP PROGRAM</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f4d4c-3bd1-4b0d-b6d3-c72560331a07",
   "metadata": {},
   "source": [
    "<h2><center><u>Assignment_6</u></center><h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0afe87-47a5-42f3-b880-c86d7460010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the useful Libraries\n",
    "\n",
    "\n",
    "#dataFrame manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# pd.set_option(\"Display.max_columns\", None)\n",
    "# pd.set_option(\"Display.max_rows\", None)\n",
    "\n",
    "\n",
    "#importing algorithms and scikit learn libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10931b6f-f468-49f5-8fab-3dd7c0679657",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement  1:**</span>\n",
    "Load the \"Breast_Cancer_Dataset.csv\" dataset into a DataFrame and perform the following task:\n",
    "1. Identify the null values and remove the null rows and columns by using the dropna() function\n",
    "2. Encode the 'diagnosis' column using the LabelEncoder()\n",
    "3. Considering the 'diagnosis' column as the target, separate the target variable and the feature vectors\n",
    "4. Split the dataset into the training set and test set in a 70:30 ratio\n",
    "5. Building a Logistic Regression, Naive Bayes, Decision Tree (CART), K-NN, SVM, and RandomForestClassifier models; Also print their accuracies\n",
    "6. Calculate and plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafa4ce-32d9-4c36-b8df-7ab48de4ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df = pd.read_csv(\"./../Assignment_files/Assignment6/Breast_Cancer_Dataset.csv\")\n",
    "bc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52075410-412b-45fc-84bf-7cb9b6789a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task1: identify the null values\n",
    "print(\"number of duplicated entries:\", bc_df.duplicated().sum())\n",
    "print(\"shape of the dataset\", bc_df.shape)\n",
    "print(bc_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d3ecd-5244-4f5c-b1b8-4345519a8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the null rows and columns by using the dropna() function\n",
    "bc_df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26f03b-d30a-453e-8a0b-16dd5ffc81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2: Encoding the \"diagnosis\" column\n",
    "label_encoder = LabelEncoder()\n",
    "encodings = label_encoder.fit_transform(bc_df[\"diagnosis\"])\n",
    "bc_df[\"diagnosis\"] = encodings\n",
    "#the mapping of values to the labels\n",
    "# mapping_values = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "# print(mapping_values)\n",
    "bc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0bb2bf-6b28-498f-b7fc-0440cc0895e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3: Separating the target variable from the feature vectors\n",
    "X = bc_df.drop(\"diagnosis\", axis=1)\n",
    "y = bc_df[\"diagnosis\"]\n",
    "\n",
    "\n",
    "\n",
    "#Task4: splitting the dataset into training set and test set in a 70:30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b98e3-a36a-45c7-8eed-4dfb1397a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"log_reg\" : LogisticRegression(),\n",
    "    \"gnb_clf\" : GaussianNB(),\n",
    "    \"rdf_clf\" : RandomForestClassifier(),\n",
    "    \"dt_clf\" : DecisionTreeClassifier(),\n",
    "    \"knn_clf\" : KNeighborsClassifier(),\n",
    "    \"sv_clf\" : SVC(probability=True)\n",
    "}\n",
    "\n",
    "model_confusionMatrix = {\n",
    "    \"log_reg\" : None,\n",
    "    \"gnb_clf\" : None,\n",
    "    \"rdf_clf\" : None,\n",
    "    \"dt_clf\" : None,\n",
    "    \"knn_clf\" : None,\n",
    "    \"sv_clf\" : None\n",
    "}\n",
    "\n",
    "model_f1_score = {\n",
    "    \"log_reg\" : None,\n",
    "    \"gnb_clf\" : None,\n",
    "    \"rdf_clf\" : None,\n",
    "    \"dt_clf\" : None,\n",
    "    \"knn_clf\" : None,\n",
    "    \"sv_clf\" : None\n",
    "}\n",
    "\n",
    "model_classification_reports = {\n",
    "    \"log_reg\" : None,\n",
    "    \"gnb_clf\" : None,\n",
    "    \"rdf_clf\" : None,\n",
    "    \"dt_clf\" : None,\n",
    "    \"knn_clf\" : None,\n",
    "    \"sv_clf\" : None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721abdd-d28c-4718-8554-f56172ec1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model) in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    # train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    # print(f\"The training score for {name} is : {train_score}\")\n",
    "    print(f\"The test score for {name} is : {test_score}\")\n",
    "    print(\"\\n------\\n\")\n",
    "    #Task 6 ploting the confusion matrix\n",
    "    y_preds = model.predict(X_test)\n",
    "    model_confusionMatrix[name] = confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ea552-265e-48ac-8a89-6078bb749a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, matrix) in model_confusionMatrix.items():\n",
    "    disp = ConfusionMatrixDisplay(matrix)\n",
    "    fig, ax = plt.subplots()\n",
    "    disp.plot(ax=ax)\n",
    "    ax.set_title(f\"Confusion matrix for {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb9169-27fe-4330-b9d9-2b81659095b6",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement  2:**</span>\n",
    "Load the 'Breast_Cancer_Dataset.csv' dataset into a DataFrame and perform the following task:\n",
    "1. Identify the null values and remove the null rows and columns by using the dropna() function\n",
    "2. Considering the 'diagnosis' column as the target, encode the 'diagnosis' column using the LabelEncoder()\n",
    "3. Separate the target variable and the feature vectors\n",
    "4. Split the dataset into the training set and test set in a 70:30 ratio\n",
    "5. Building a Logistic Regression, Naive Bayes, Decision Tree(CART), K-NN, SVM, and RandomForestClassifier models; Also, print their accuraries\n",
    "6. Calculate the ROC_AUC score based on the False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "7. Plot the ROC Curve using the Matplotlib library\n",
    "8. Calculate the F1 Score\n",
    "9. Calculate and print the Precision, Recall, and F1 score usig the classification_report() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768e32b-6ce4-4ba9-97ff-85a7de280321",
   "metadata": {},
   "source": [
    "task 1, 2, 3, 4, 5 have been handled in problem statement 1\n",
    "In the section I will be calculating the ROC_AUC score based on the False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "plotting the ROC Curve using the Matplotlib library\n",
    "Calculating the F1 score\n",
    "Printing the precision, recall and F1 score using the classification_report() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f79695-acd4-4961-b214-c32ac8dc5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_preds = model.predict(X_test)\n",
    "    #calculating the fpr, and tpr rates for the \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    model_f1_score[name] = f1_score(y_test, y_preds)\n",
    "    model_classification_reports[name] = classification_report(y_test, y_preds)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, label='ROC curve (area =%0.2f)' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], 'r--', label=name) \n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC curve for %s' % name)\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1023d-7758-4627-bf36-18410bdda87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"The F1 score of the is model({name}) is {model_f1_score[name]}\")\n",
    "    print(\"Classification report for %s\" % name)\n",
    "    print(model_classification_reports[name])\n",
    "    print(\" \\n---- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573373f0-0272-4f86-be19-73781a9ae372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceff8b4-9984-4e64-b043-a51b6ea9b09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f5ded6-fa70-486b-a26b-160b23712957",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement  3:**</span>\n",
    "Load the 'voice.csv' dataset into a DataFrame and perform the following tasks:\n",
    "1. Considering the 'label' column as the target variable, rename the column as 'Gender_Identified'\n",
    "2. Using the preprocessing() function, label the target column\n",
    "3. Separate the target variable and the feature vectors\n",
    "4. Build a RandomForestClassifier model and find the best parameters using a Grid search\n",
    "5. Print the best parameters and the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c0206-d8cd-4b27-aa53-8abb36dc3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_df = pd.read_csv(\"./../Assignment_files/Assignment6/voice.csv\")\n",
    "voice_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c817605-0d52-4f04-81b8-d81565a4c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Renaming the label column as 'Gender_Identified'\n",
    "voice_df.rename({\"label\":\"Gender_Identified\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e55bcf-aa5b-49f2-9c78-73f459841837",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa02883-22ca-4a7e-ba25-13513733feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cfb5c5-299f-4611-9f62-2c8574f86514",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8eace-2c79-456e-a856-7f1bd286c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2: Using the preprocessing fucntion to label the target column\n",
    "encode = LabelEncoder()\n",
    "\n",
    "voice_df[\"Gender_Identified\"] = encode.fit_transform(voice_df[\"Gender_Identified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3f6f3-b0a5-44ca-8dee-2f9bbe011e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48537e36-ecf2-46c7-9d3a-5ab47110efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c6b99-ffb5-46ab-87e0-d537f6dae4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task3: Separating the target variable and the feature vectors\n",
    "voice_data = voice_df.drop(\"Gender_Identified\", axis=1)\n",
    "voice_target = voice_df[\"Gender_Identified\"]\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941210fb-a8fc-4c51-a0a8-0b4cd3bacbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_clf = RandomForestClassifier()\n",
    "params = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "    \n",
    "clf = GridSearchCV(rdf_clf, param_grid=params)\n",
    "clf.fit(voice_data, voice_target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf8bec-617e-4f24-9f42-1cbc48c10f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The best parameters are:\\n{clf.best_params_}\")\n",
    "print('\\n')\n",
    "print(f\"The best estimator is: \\n{clf.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90813e45-d1e7-4f35-acd6-e408e6a6a1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad6052-5c41-42d6-8fec-af967fa35014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae30e9b0-d013-41f1-aa03-8816b357ad4b",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement  4:**</span>\n",
    "The 'seeds.csv' dataset contains the data about the wheat seeds, the 'Type' column consist of three unique values, 1, 2, 3, which are classified based on the characteristics of seeds entailing in other columns\n",
    "\n",
    "\n",
    "Load the 'seeds.csv' dataset into a DataFrame and perform the following tasks:\n",
    "1. Considering the 'Type' column as target, analyse the target column by printing the unique values\n",
    "2. Separate the feature vectors and the target variable\n",
    "3. Split the dataset into train and test sets in a 70:30 ratio\n",
    "4. Build a Decision Tree Classifier and a GuassianNB model and print their accuracy scores\n",
    "5. For the Decision Tree Classifier and a GuassianNB models boost the accuracy using ADA Boost Classifier and compare the accuracy scores with original models using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75802844-5ac0-4f47-9e18-d3acb3891cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_df = pd.read_csv(\"./../Assignment_files/Assignment6/seeds.csv\")\n",
    "seed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe62b1-5580-4149-9342-a5d76b389725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Considering the 'Type' Column as target, analyze the target column by printing the unique values\n",
    "counts = seed_df[\"Type\"].value_counts()\n",
    "percentage = seed_df[\"Type\"].value_counts()/seed_df[\"Type\"].count()\n",
    "unique_type = pd.DataFrame({\"Counts\":counts, \"Percentage\":percentage})\n",
    "unique_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb426110-2dcf-47fb-bff1-4c2827b66e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2: Separating the feature vectors and the target variable\n",
    "X = seed_df.drop(\"Type\", axis=1)\n",
    "y = seed_df[\"Type\"]\n",
    "\n",
    "#Task3: Spliting the dataset into train and test sets in a 70:30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#Task 4: Building a Decision Tree Classifier and a GaussianNB model and print their accuracy scores\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "#for decision tree classifier\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_y_preds = dt_clf.predict(X_test)\n",
    "dt_acc_score = accuracy_score(y_test, dt_y_preds)\n",
    "\n",
    "#for gaussianNB classifier\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_preds = gnb_clf.predict(X_test)\n",
    "gnb_acc_score = accuracy_score(y_test, gnb_y_preds)\n",
    "\n",
    "print(f\"\"\"\n",
    "Accuracy score of the Decision tree model is:\n",
    "{dt_acc_score}\n",
    "\n",
    "Accuracy score of the GaussianNB model is:\n",
    "{gnb_acc_score}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df8e1e-1b1b-4095-8a2d-09bc308ae122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 5: Boosting the model accuracy using ADA Boost Classifier and comparing the accuracy scores with original models \n",
    "\n",
    "dt_AdaBoost = AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=42)\n",
    "gnb_AdaBoost =  AdaBoostClassifier(estimator=GaussianNB(), random_state=42)\n",
    "\n",
    "#for dt_classifier\n",
    "dt_AdaBoost.fit(X_train, y_train)\n",
    "dt_AdaBoost_preds = dt_AdaBoost.predict(X_test)\n",
    "dt_AdaBoost_acc = accuracy_score(y_test, dt_AdaBoost_preds)\n",
    "\n",
    "#for gnb classifier\n",
    "gnb_AdaBoost.fit(X_train, y_train)\n",
    "gnb_AdaBoost_preds = gnb_AdaBoost.predict(X_test)\n",
    "gnb_AdaBoost_acc = accuracy_score(y_test, gnb_AdaBoost_preds)\n",
    "\n",
    "print(f\"\"\"\n",
    "Accuracy score of the Boosted Decision tree model is:\n",
    "{dt_AdaBoost_acc}\n",
    "\n",
    "Accuracy score of the Boosted GaussianNB model is:\n",
    "{gnb_AdaBoost_acc}\n",
    "\"\"\")\n",
    "\n",
    "#comparing the boosted accuracies using a bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "clfs = [\"Decision Tree\", \"GausianNB\", \"AdaBoost(Decision Tree)\", \"AdaBoost(GaussianNB)\"]\n",
    "clf_scores = [dt_acc_score,  gnb_acc_score, dt_AdaBoost_acc, gnb_AdaBoost_acc]\n",
    "labels = clfs\n",
    "bar_colors = ['tab:red', 'tab:blue', 'tab:green', 'tab:orange']\n",
    "hbars = ax.barh(clfs, clf_scores, label=labels, color=bar_colors)\n",
    "ax.set_xlabel(\"Accuracy score (between 0 and 1)\")\n",
    "ax.bar_label(hbars, fmt=\"%.2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93c2ae-2cbc-4a98-856f-164ab3490931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
