{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964cc2cb-fa56-4a00-9ed5-9da21c426933",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue\">DATA SCIENCE AND MACHINE LEARNING INTERNSHIP PROGRAM</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f4638-5ed1-414e-ba4e-a6e1e34430ac",
   "metadata": {},
   "source": [
    "<h2><center><u>Assignment_5</u></center><h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860b172b-326e-47d7-adc1-8934d67da9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the useful Libraries\n",
    "\n",
    "\n",
    "#dataFrame manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"Display.max_columns\", None)\n",
    "pd.set_option(\"Display.max_rows\", None)\n",
    "\n",
    "#Needed  Libraries\n",
    "\n",
    "\n",
    "#Algorithm and scikit learn libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f95cd1-295d-4c48-b267-034d22d10ba8",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement  1:**</span>\n",
    "Load the \"Country-data.csv\" dataset into a DataFrame and perform the following tasks:\n",
    "1. Create a seperate DataFrame with only numeric data by remove the \"country\" column\n",
    "2. Scale the data using the Standard Scaler to create a scaled DataFrame\n",
    "3. Plotting dendograms with the complete linkage method\n",
    "4. Creating cluster labels using cut tree\n",
    "5. Perfom the 4-Component PCA on DataFrame\n",
    "6. Now, from final the DataFrame, analyze how low GDP rate corresponds to the child mortality rate around the world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a51f18-2ded-4b27-af56-e50bfe825cc3",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\"> **Problem Statement 2:**</span>\n",
    "Write a Python program that reads the \"Credit Card Customer Data.csv\". The following are the tasks that need to be taken into consideration while constructing the solution to Segregate customers based on the data provided with the help of k-means clustering.\n",
    "\n",
    "**Task to be performed:**\n",
    "1. Load the Given CSV file into a DataFrame\n",
    "2. Find missing values and drop the unnecessary columns\n",
    "3. Univariate and bivariate analysis\n",
    "4. Standardize the whole dataset\n",
    "5. Find the within-cluster sum of square\n",
    "6. Find silhouette score\n",
    "7. Use a line plot using matplotlib to find scores for different sizes of K and choose the best size of the cluster and build the final model\n",
    "8. Observe Cluster behavior with different columns\n",
    "9. Print Co-ordinates of all centroid and silhouette scores for the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a507aa-3687-4faa-8a81-f130047b2e02",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement 3:**</span> **DBSCAN Clustering**\n",
    "Load the \"Mall_Customers.csv\" dataset into a DataFrame to perform the following task:\n",
    "1. Find the correlation among the all the columns and drop the column/s with the least correlation\n",
    "2. Encode the \"Gender\" column using get_dummies() function\n",
    "3. Perform Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering with eps=12.5 and min_samples=4\n",
    "4. Print the size of each cluster and also the size of outliers' cluster\n",
    "5. Using a scatter plot shows how annual income corresponds to the spending rates of customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67272000-dce4-4689-9bd5-c229052099a4",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">**Problem Statement 4:**</span>\n",
    "Write a python program that reads the Groceries data.csv file into a DataFrame. The following are the tasks that need to be taken into consideration while constructing the solution to using the apriori algorithm and list out items that are sold most frequently with other items. Dataset file contains tabular data, where it has items, date, member number, day of the month, day of the week, etc.\n",
    "**Tasks to be performed:**\n",
    "1. Install mlxtend library for futher process\n",
    "2. Load the Groceries data.csv data into a Data frame\n",
    "3. Print customer data where the member number is 1001\n",
    "4. Create a new column as \"item count\", and give the count as 1 (because all customers bought 1 item on each day only)\n",
    "5. Drop unnecessary columns lik \"month\", \"day\", \"year\", \"day_of_week\"\n",
    "6. Create a new data frame where all data is grouped by member id and items they bought and set their value as itme count\n",
    "7. Use the Apriori algorithm and generate frequent itemsets that have the support of at least 7%\n",
    "8. Generating the rules with their corresponding support, confidence , and lift\n",
    "9. Filtering out the values with lift >= 1 and confidemce >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435d443-a420-4a61-a5c7-c1feca429891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
